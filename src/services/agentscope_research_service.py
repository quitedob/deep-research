#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AgentScopeç ”ç©¶æœåŠ¡
æä¾›æ·±åº¦ç ”ç©¶åŠŸèƒ½çš„ä¸»è¦æœåŠ¡æ¥å£
"""

import asyncio
import uuid
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Union
from src.services.base_service import BaseService

# å¯¼å…¥è‡ªå®šä¹‰ç»„ä»¶
from src.core.agentscope.research_agent import DeepResearchAgent
from src.core.agentscope.memory.research_memory import ResearchMemoryManager
from src.dao.research_dao import ResearchDAO

# å¯¼å…¥LLMæŠ½è±¡å±‚
from src.core.llm.factory import LLMFactory
from src.core.llm.base_llm import BaseLLM, ConfigurationError
from src.config.llm_config import get_config


class AgentScopeResearchService(BaseService):
    """
    AgentScopeç ”ç©¶æœåŠ¡
    ç®¡ç†æ·±åº¦ç ”ç©¶çš„ç”Ÿå‘½å‘¨æœŸå’Œåè°ƒå„ä¸ªç»„ä»¶
    """

    def __init__(self, llm_provider: str = "deepseek"):
        """
        åˆå§‹åŒ–ç ”ç©¶æœåŠ¡
        
        Args:
            llm_provider: LLMæä¾›å•†åç§° (é»˜è®¤: "deepseek")
        """
        super().__init__()
        self.research_dao = ResearchDAO()
        self.memory_manager = ResearchMemoryManager(self.research_dao)
        self.active_researchers: Dict[str, DeepResearchAgent] = {}
        
        # âœ… å¯¼å…¥ ChatDAO ç”¨äºä¿å­˜åˆ°èŠå¤©å†å²
        from src.dao.chat_dao import ChatDAO
        self.chat_dao = ChatDAO()
        
        # å†…å­˜ä¸­çš„ä¼šè¯ä¿¡æ¯ï¼ˆç”¨äºæ•°æ®åº“æœªå¯ç”¨æ—¶ï¼‰
        self.session_cache: Dict[str, Dict[str, Any]] = {}
        
        # âœ… æŠ¥å‘Šç¼“å­˜ - ç ”ç©¶å®Œæˆåç¼“å­˜å®Œæ•´æŠ¥å‘Šï¼Œé¿å…é‡å¤ç”Ÿæˆ
        self.report_cache: Dict[str, Dict[str, Any]] = {}
        
        # è®¾ç½®é»˜è®¤LLMæä¾›å•†
        self.llm_provider = llm_provider
        
        # ä½¿ç”¨LLMå·¥å‚åˆ›å»ºé»˜è®¤LLMå®ä¾‹
        try:
            self.default_llm = LLMFactory.create_llm(provider=llm_provider)
        except ConfigurationError as e:
            # å¦‚æœé…ç½®å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ä¸é˜»æ­¢æœåŠ¡åˆå§‹åŒ–
            print(f"è­¦å‘Š: æ— æ³•åˆå§‹åŒ–é»˜è®¤LLM ({llm_provider}): {str(e)}")
            self.default_llm = None
        
        # è·å–é…ç½®
        self.config = get_config()
        
        # åˆ›å»ºé»˜è®¤å¤šæ¨¡æ€LLMå®ä¾‹ï¼ˆç”¨äºOllamaå›¾åƒåˆ†æï¼‰
        try:
            self.default_multimodal_llm = LLMFactory.create_llm(
                provider="ollama",
                base_url="http://localhost:11434",
                model="gemma3:4b"
            )
        except ConfigurationError as e:
            print(f"è­¦å‘Š: æ— æ³•åˆå§‹åŒ–å¤šæ¨¡æ€LLM (Ollama): {str(e)}")
            self.default_multimodal_llm = None

    async def start_research(
        self,
        query: str,
        user_id: Optional[str] = None,
        research_type: str = "comprehensive",
        sources: Optional[List[str]] = None,
        include_images: bool = False,
        llm_provider: Optional[str] = None,
        multimodal_llm_instance: Optional[BaseLLM] = None,
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        å¯åŠ¨æ·±åº¦ç ”ç©¶

        Args:
            query: ç ”ç©¶æŸ¥è¯¢
            user_id: ç”¨æˆ·ID
            research_type: ç ”ç©¶ç±»å‹
            sources: æŒ‡å®šçš„ä¿¡æ¯æºç±»å‹
            include_images: æ˜¯å¦åŒ…å«å›¾åƒåˆ†æ
            llm_provider: LLMæä¾›å•†åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æœåŠ¡çš„é»˜è®¤æä¾›å•†ï¼‰
            multimodal_llm_instance: è‡ªå®šä¹‰å¤šæ¨¡æ€LLMå®ä¾‹ï¼ˆå¯é€‰ï¼‰
            session_id: æŒ‡å®šä¼šè¯IDï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ

        Returns:
            ç ”ç©¶å¯åŠ¨ç»“æœ
        """
        try:
            # ç”Ÿæˆæˆ–éªŒè¯ä¼šè¯ID
            if not session_id:
                session_id = str(uuid.uuid4())
            elif session_id in self.active_researchers:
                return {
                    "success": False,
                    "error": "ç ”ç©¶ä¼šè¯å·²å­˜åœ¨",
                    "session_id": session_id
                }

            # ç¡®å®šä½¿ç”¨çš„LLMæä¾›å•†
            provider = llm_provider or self.llm_provider
            
            # åˆ›å»ºæˆ–è·å–LLMå®ä¾‹
            try:
                if provider == self.llm_provider and self.default_llm:
                    llm_instance = self.default_llm
                else:
                    llm_instance = LLMFactory.create_llm(provider=provider)
            except ConfigurationError as e:
                return {
                    "success": False,
                    "error": f"LLMé…ç½®é”™è¯¯: {str(e)}",
                    "session_id": session_id
                }
            
            # éªŒè¯DeepSeek APIå¯†é’¥ï¼ˆå¦‚æœä½¿ç”¨DeepSeekï¼‰
            if provider == "deepseek":
                provider_config = self.config.get_provider_config("deepseek")
                if not provider_config.api_key:
                    return {
                        "success": False,
                        "error": "DeepSeek APIå¯†é’¥æœªé…ç½®ã€‚è¯·è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡ã€‚",
                        "session_id": session_id
                    }

            # ç¡®å®šä½¿ç”¨çš„å¤šæ¨¡æ€LLMå®ä¾‹
            final_multimodal_llm = multimodal_llm_instance or self.default_multimodal_llm

            # è·å–APIå¯†é’¥
            web_search_api_key = await self._get_web_search_api_key()
            if not web_search_api_key:
                return {
                    "success": False,
                    "error": "ç½‘ç»œæœç´¢APIå¯†é’¥æœªé…ç½®"
                }

            # åˆ›å»ºç ”ç©¶ä»£ç†ï¼Œä¼ å…¥LLMå®ä¾‹
            researcher = DeepResearchAgent(
                session_id=session_id,
                llm_instance=llm_instance,
                multimodal_llm_instance=final_multimodal_llm,
                web_search_api_key=web_search_api_key
            )

            # å¼‚æ­¥åˆå§‹åŒ–ç ”ç©¶ä»£ç†
            await researcher.async_init()

            # å­˜å‚¨æ´»è·ƒç ”ç©¶è€…
            self.active_researchers[session_id] = researcher

            # åœ¨æ•°æ®åº“ä¸­åˆ›å»ºä¼šè¯è®°å½•
            await self.research_dao.create_research_session(
                session_id=session_id,
                user_id=user_id,
                title=f"ç ”ç©¶: {query[:50]}..."
            )
            
            # åŒæ—¶åœ¨å†…å­˜ä¸­ç¼“å­˜ä¼šè¯ä¿¡æ¯ï¼ˆç”¨äºæ•°æ®åº“æœªå¯ç”¨æ—¶ï¼‰
            self.session_cache[session_id] = {
                "id": session_id,
                "user_id": user_id,
                "title": f"ç ”ç©¶: {query[:50]}...",
                "status": "active",
                "created_at": datetime.now().isoformat()
            }

            # å¯åŠ¨å¼‚æ­¥ç ”ç©¶ï¼Œå¹¶åœ¨å®Œæˆåè‡ªåŠ¨ç”ŸæˆæŠ¥å‘Š
            async def research_with_completion():
                """ç ”ç©¶å®Œæˆåè‡ªåŠ¨ç”Ÿæˆå¹¶ç¼“å­˜æŠ¥å‘Š"""
                try:
                    result = await researcher.conduct_research(
                        query=query,
                        research_type=research_type,
                        sources=sources,
                        include_images=include_images
                    )
                    
                    # âœ… ç ”ç©¶å®Œæˆåï¼Œç«‹å³ç”Ÿæˆå®Œæ•´æŠ¥å‘Šå¹¶ç¼“å­˜
                    print(f"âœ“ ç ”ç©¶å®Œæˆï¼Œå¼€å§‹ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
                    
                    try:
                        final_report = await self._generate_final_report(session_id, researcher)
                        
                        # ç¼“å­˜å®Œæ•´æŠ¥å‘Š
                        if final_report:
                            self.report_cache[session_id] = final_report
                            print(f"âœ“ æŠ¥å‘Šå·²ç”Ÿæˆå¹¶ç¼“å­˜")
                        else:
                            print(f"âš ï¸ æŠ¥å‘Šç”Ÿæˆè¿”å›ç©ºå€¼")
                    except Exception as report_error:
                        print(f"âš ï¸ ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {str(report_error)}")
                        import traceback
                        traceback.print_exc()
                        # å³ä½¿æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œä¹Ÿç»§ç»­æ›´æ–°çŠ¶æ€
                    
                    # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸ºå·²å®Œæˆï¼ˆå³ä½¿æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼‰
                    try:
                        await self.research_dao.update_session_status(
                            session_id,
                            "completed",
                            datetime.now()
                        )
                        print(f"âœ“ ä¼šè¯çŠ¶æ€å·²æ›´æ–°ä¸º completed")
                    except Exception as db_error:
                        print(f"âš ï¸ æ›´æ–°æ•°æ®åº“çŠ¶æ€å¤±è´¥: {str(db_error)}")
                        # æ•°æ®åº“æ›´æ–°å¤±è´¥ä¸å½±å“ç ”ç©¶ç»“æœ
                    
                    # âœ… ä¿å­˜ç ”ç©¶ç»“æœåˆ°èŠå¤©å†å²è®°å½•
                    try:
                        await self._save_research_to_chat_history(session_id, query, result)
                    except Exception as save_error:
                        print(f"âš ï¸ ä¿å­˜åˆ°èŠå¤©å†å²å¤±è´¥: {str(save_error)}")
                        # ä¿å­˜å¤±è´¥ä¸å½±å“ç ”ç©¶ç»“æœ
                    
                    print(f"âœ“ ä¼šè¯ {session_id} å®Œæˆ")
                    return result
                    
                except Exception as e:
                    print(f"âœ— ç ”ç©¶å¤±è´¥: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    
                    # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸ºå¤±è´¥
                    try:
                        await self.research_dao.update_session_status(
                            session_id,
                            "failed",
                            datetime.now()
                        )
                    except Exception as db_error:
                        print(f"âš ï¸ æ›´æ–°å¤±è´¥çŠ¶æ€æ—¶å‡ºé”™: {str(db_error)}")
                    
                    raise
            
            research_task = asyncio.create_task(research_with_completion())

            # å­˜å‚¨ä»»åŠ¡å¼•ç”¨
            self.active_researchers[session_id]._research_task = research_task

            return {
                "success": True,
                "session_id": session_id,
                "status": "started",
                "message": "ç ”ç©¶å·²å¯åŠ¨",
                "started_at": datetime.now().isoformat()
            }

        except Exception as e:
            # æ‰“å°è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            import traceback
            print(f"å¯åŠ¨ç ”ç©¶æ—¶å‡ºé”™: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            print("å®Œæ•´å †æ ˆ:")
            traceback.print_exc()
            
            # æ¸…ç†å¤±è´¥çš„ä¼šè¯
            if session_id and session_id in self.active_researchers:
                del self.active_researchers[session_id]

            return {
                "success": False,
                "error": f"å¯åŠ¨ç ”ç©¶å¤±è´¥: {str(e)}",
                "session_id": session_id
            }

    async def get_research_status(self, session_id: str) -> Dict[str, Any]:
        """
        è·å–ç ”ç©¶çŠ¶æ€

        Args:
            session_id: ä¼šè¯ID

        Returns:
            ç ”ç©¶çŠ¶æ€ä¿¡æ¯
        """
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ´»è·ƒä¼šè¯
            if session_id in self.active_researchers:
                researcher = self.active_researchers[session_id]

                # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                if hasattr(researcher, '_research_task'):
                    task = researcher._research_task
                    if task.done():
                        # âœ… ä»»åŠ¡å®Œæˆï¼Œä»æ´»è·ƒåˆ—è¡¨ä¸­ç§»é™¤
                        del self.active_researchers[session_id]
                        
                        try:
                            result = task.result()
                            return {
                                "session_id": session_id,
                                "status": "completed",
                                "result": result,
                                "completed_at": datetime.now().isoformat()
                            }
                        except Exception as e:
                            return {
                                "session_id": session_id,
                                "status": "failed",
                                "error": str(e),
                                "failed_at": datetime.now().isoformat()
                            }

                # è·å–å½“å‰çŠ¶æ€
                status = await researcher.get_research_status()
                return {
                    "session_id": session_id,
                    "status": "in_progress",
                    "progress": status,
                    "updated_at": datetime.now().isoformat()
                }

            # âœ… æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„æŠ¥å‘Šï¼ˆå·²å®Œæˆçš„ä¼šè¯ï¼‰
            if session_id in self.report_cache:
                return {
                    "session_id": session_id,
                    "status": "completed",
                    "note": "ç ”ç©¶å·²å®Œæˆï¼ŒæŠ¥å‘Šå·²ç¼“å­˜",
                    "completed_at": datetime.now().isoformat()
                }

            # æ£€æŸ¥æ•°æ®åº“ä¸­çš„ä¼šè¯
            session_info = await self.research_dao.get_research_session(session_id)
            if session_info:
                return {
                    "session_id": session_id,
                    "status": session_info["status"],
                    "session_info": session_info,
                    "note": "ä¼šè¯å·²å®Œæˆæˆ–å·²ä¸­æ–­"
                }

            return {
                "session_id": session_id,
                "status": "not_found",
                "error": "ç ”ç©¶ä¼šè¯ä¸å­˜åœ¨"
            }

        except Exception as e:
            return {
                "session_id": session_id,
                "status": "error",
                "error": f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}"
            }

    async def interrupt_research(self, session_id: str) -> Dict[str, Any]:
        """
        ä¸­æ–­ç ”ç©¶ä¼šè¯

        Args:
            session_id: ä¼šè¯ID

        Returns:
            ä¸­æ–­ç»“æœ
        """
        try:
            if session_id not in self.active_researchers:
                return {
                    "success": False,
                    "error": "ç ”ç©¶ä¼šè¯ä¸å­˜åœ¨æˆ–å·²ç»“æŸ",
                    "session_id": session_id
                }

            researcher = self.active_researchers[session_id]

            # ä¸­æ–­ç ”ç©¶
            interrupt_result = await researcher.interrupt_research()

            # ä»æ´»è·ƒåˆ—è¡¨ä¸­ç§»é™¤
            del self.active_researchers[session_id]

            # æ›´æ–°æ•°æ®åº“çŠ¶æ€
            await self.research_dao.update_session_status(
                session_id,
                "interrupted",
                datetime.now()
            )

            return {
                "success": True,
                "session_id": session_id,
                "interrupt_result": interrupt_result,
                "message": "ç ”ç©¶å·²ä¸­æ–­"
            }

        except Exception as e:
            return {
                "success": False,
                "error": f"ä¸­æ–­ç ”ç©¶å¤±è´¥: {str(e)}",
                "session_id": session_id
            }

    async def resume_research(
        self,
        session_id: str,
        state_data: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ¢å¤è¢«ä¸­æ–­çš„ç ”ç©¶

        Args:
            session_id: ä¼šè¯ID
            state_data: ä¿å­˜çš„çŠ¶æ€æ•°æ®

        Returns:
            æ¢å¤ç»“æœ
        """
        try:
            if session_id in self.active_researchers:
                return {
                    "success": False,
                    "error": "ç ”ç©¶ä¼šè¯å·²å­˜åœ¨",
                    "session_id": session_id
                }

            # è·å–ä¿å­˜çš„çŠ¶æ€æ•°æ®
            if not state_data:
                session_data = await self.research_dao.export_session_data(session_id)
                if not session_data:
                    return {
                        "success": False,
                        "error": "æ— æ³•è·å–ä¼šè¯çŠ¶æ€æ•°æ®",
                        "session_id": session_id
                    }
                state_data = session_data

            # é‡å»ºç ”ç©¶ä»£ç†
            web_search_api_key = await self._get_web_search_api_key()
            
            # åˆ›å»ºLLMå®ä¾‹
            try:
                llm_instance = self.default_llm or LLMFactory.create_llm(provider=self.llm_provider)
            except ConfigurationError as e:
                return {
                    "success": False,
                    "error": f"LLMé…ç½®é”™è¯¯: {str(e)}",
                    "session_id": session_id
                }
            
            researcher = DeepResearchAgent(
                session_id=session_id,
                llm_instance=llm_instance,
                multimodal_llm_instance=self.default_multimodal_llm,
                web_search_api_key=web_search_api_key
            )

            # æ¢å¤çŠ¶æ€
            recovery_success = await researcher.resume_research(state_data)
            if not recovery_success:
                return {
                    "success": False,
                    "error": "æ¢å¤ä¼šè¯çŠ¶æ€å¤±è´¥",
                    "session_id": session_id
                }

            # é‡æ–°æ¿€æ´»ä¼šè¯
            self.active_researchers[session_id] = researcher
            await self.research_dao.update_session_status(session_id, "active")

            return {
                "success": True,
                "session_id": session_id,
                "message": "ç ”ç©¶ä¼šè¯å·²æ¢å¤"
            }

        except Exception as e:
            return {
                "success": False,
                "error": f"æ¢å¤ç ”ç©¶å¤±è´¥: {str(e)}",
                "session_id": session_id
            }

    async def get_user_sessions(
        self,
        user_id: str,
        status: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        è·å–ç”¨æˆ·çš„ç ”ç©¶ä¼šè¯åˆ—è¡¨

        Args:
            user_id: ç”¨æˆ·ID
            status: è¿‡æ»¤çŠ¶æ€
            limit: ç»“æœæ•°é‡é™åˆ¶

        Returns:
            ä¼šè¯åˆ—è¡¨
        """
        try:
            # å°è¯•ä»æ•°æ®åº“è·å–
            db_sessions = await self.research_dao.get_user_research_sessions(
                user_id=user_id,
                status=status,
                limit=limit
            )
            
            if db_sessions:
                return db_sessions
            
            # å¦‚æœæ•°æ®åº“æœªå¯ç”¨ï¼Œä»ç¼“å­˜è·å–
            cached_sessions = []
            for session_id, session_info in self.session_cache.items():
                if session_info.get("user_id") == user_id:
                    if status is None or session_info.get("status") == status:
                        cached_sessions.append({
                            "id": session_id,
                            "user_id": session_info.get("user_id"),
                            "title": session_info.get("title"),
                            "status": session_info.get("status"),
                            "created_at": session_info.get("created_at"),
                            "updated_at": session_info.get("created_at"),
                            "ended_at": None,
                            "findings_count": 0,
                            "citations_count": 0
                        })
            
            return cached_sessions[:limit]
            
        except Exception as e:
            print(f"è·å–ç”¨æˆ·ä¼šè¯å¤±è´¥: {str(e)}")
            return []

    async def export_session_data(self, session_id: str) -> Optional[Dict[str, Any]]:
        """
        å¯¼å‡ºä¼šè¯æ•°æ®

        Args:
            session_id: ä¼šè¯ID

        Returns:
            ä¼šè¯æ•°æ®å­—å…¸
        """
        try:
            # âœ… ä¼˜å…ˆä»ç¼“å­˜è·å–å®Œæ•´æŠ¥å‘Šï¼ˆç ”ç©¶å®Œæˆåï¼‰
            if session_id in self.report_cache:
                print(f"âœ“ ä»ç¼“å­˜è¿”å›æŠ¥å‘Š (ä¼šè¯: {session_id})")
                return self.report_cache[session_id]
            
            # å¦‚æœæ˜¯æ´»è·ƒä¼šè¯ï¼Œä»ä»£ç†è·å–æ•°æ®
            if session_id in self.active_researchers:
                researcher = self.active_researchers[session_id]
                agent_data = await researcher.export_session_data()
                
                # è½¬æ¢æ ¼å¼ä»¥åŒ¹é… API æœŸæœ›
                if agent_data:
                    # è·å–ç¼“å­˜çš„ä¼šè¯ä¿¡æ¯
                    cached_session = self.session_cache.get(session_id, {})
                    
                    # ç¡®ä¿æ—¥æœŸæ—¶é—´å­—æ®µæ˜¯å­—ç¬¦ä¸²æ ¼å¼
                    created_at = agent_data.get("created_at")
                    if isinstance(created_at, datetime):
                        created_at = created_at.isoformat()
                    elif not created_at:
                        created_at = cached_session.get("created_at", datetime.now().isoformat())
                    
                    updated_at = agent_data.get("last_updated")
                    if isinstance(updated_at, datetime):
                        updated_at = updated_at.isoformat()
                    elif not updated_at:
                        updated_at = datetime.now().isoformat()
                    
                    # âœ… ä½¿ç”¨ agent ç”Ÿæˆçš„æŠ¥å‘Šï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”Ÿæˆä¸€ä¸ª
                    report = agent_data.get("report")
                    if not report:
                        report = await self._generate_report_from_data(
                            agent_data.get("research_findings", []),
                            agent_data.get("citations", []),
                            cached_session.get("title", "ç ”ç©¶ä¼šè¯")
                        )
                    
                    # ç¡®å®šä¼šè¯çŠ¶æ€
                    status = "completed" if agent_data.get("research_phase") == "completed" else "active"
                    
                    # âœ… åºåˆ—åŒ– findings å’Œ citationsï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯åºåˆ—åŒ–çš„
                    findings = agent_data.get("research_findings", [])
                    serialized_findings = []
                    for finding in findings:
                        serialized_finding = dict(finding) if not isinstance(finding, dict) else finding.copy()
                        # è½¬æ¢ id ä¸ºå­—ç¬¦ä¸²
                        if 'id' in serialized_finding and not isinstance(serialized_finding['id'], str):
                            serialized_finding['id'] = str(serialized_finding['id'])
                        # è½¬æ¢ created_at ä¸ºå­—ç¬¦ä¸²
                        if 'created_at' in serialized_finding:
                            if isinstance(serialized_finding['created_at'], datetime):
                                serialized_finding['created_at'] = serialized_finding['created_at'].isoformat()
                            elif not isinstance(serialized_finding['created_at'], str):
                                serialized_finding['created_at'] = str(serialized_finding['created_at'])
                        serialized_findings.append(serialized_finding)
                    
                    citations = agent_data.get("citations", [])
                    serialized_citations = []
                    for citation in citations:
                        serialized_citation = dict(citation) if not isinstance(citation, dict) else citation.copy()
                        # è½¬æ¢ id ä¸ºå­—ç¬¦ä¸²
                        if 'id' in serialized_citation and not isinstance(serialized_citation['id'], str):
                            serialized_citation['id'] = str(serialized_citation['id'])
                        # è½¬æ¢ created_at ä¸ºå­—ç¬¦ä¸²
                        if 'created_at' in serialized_citation:
                            if isinstance(serialized_citation['created_at'], datetime):
                                serialized_citation['created_at'] = serialized_citation['created_at'].isoformat()
                            elif not isinstance(serialized_citation['created_at'], str):
                                serialized_citation['created_at'] = str(serialized_citation['created_at'])
                        serialized_citations.append(serialized_citation)
                    
                    return {
                        "session_info": {
                            "id": agent_data.get("session_id", session_id),
                            "user_id": cached_session.get("user_id"),
                            "title": cached_session.get("title", "ç ”ç©¶ä¼šè¯"),
                            "status": status,
                            "created_at": created_at,
                            "updated_at": updated_at,
                            "ended_at": None,
                            "findings_count": len(serialized_findings),
                            "citations_count": len(serialized_citations)
                        },
                        "findings": serialized_findings,
                        "citations": serialized_citations,
                        "memory": agent_data.get("short_memory", []),
                        "report": report,  # âœ… æ·»åŠ æŠ¥å‘Šå­—æ®µ
                        "tools_used": agent_data.get("tools_used", []),
                        "exported_at": datetime.now().isoformat()
                    }

            # å°è¯•ä»æ•°æ®åº“è·å–
            db_data = await self.research_dao.export_session_data(session_id)
            if db_data:
                return db_data
            
            # å¦‚æœæ•°æ®åº“æœªå¯ç”¨ï¼Œä»ç¼“å­˜è·å–åŸºæœ¬ä¿¡æ¯
            if session_id in self.session_cache:
                session_info = self.session_cache[session_id]
                return {
                    "session_info": session_info,
                    "findings": [],
                    "citations": [],
                    "memory": [],
                    "exported_at": datetime.now().isoformat()
                }
            
            return None

        except Exception as e:
            print(f"å¯¼å‡ºä¼šè¯æ•°æ®å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    async def _save_research_to_chat_history(
        self,
        session_id: str,
        query: str,
        result: Dict[str, Any]
    ) -> bool:
        """
        å°†ç ”ç©¶ç»“æœä¿å­˜åˆ°èŠå¤©å†å²è®°å½•
        
        Args:
            session_id: ç ”ç©¶ä¼šè¯ID
            query: ç”¨æˆ·æŸ¥è¯¢
            result: ç ”ç©¶ç»“æœ
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # è·å–ä¼šè¯ä¿¡æ¯
            session_info = self.session_cache.get(session_id, {})
            user_id = session_info.get("user_id")
            
            if not user_id:
                print(f"âš ï¸ æ— æ³•ä¿å­˜åˆ°èŠå¤©å†å²ï¼šæœªæ‰¾åˆ° user_id")
                return False
            
            # åˆ›å»ºæˆ–è·å–èŠå¤©ä¼šè¯
            chat_session_id = session_info.get("chat_session_id")
            
            if not chat_session_id:
                # åˆ›å»ºæ–°çš„èŠå¤©ä¼šè¯
                chat_session = await self.chat_dao.create_session(
                    user_id=user_id,
                    title=f"æ·±åº¦ç ”ç©¶: {query[:30]}...",
                    llm_provider="agentscope",
                    model_name="deep-research"  # âœ… æ·»åŠ  model_name å‚æ•°
                )
                chat_session_id = chat_session.get("id")
                print(f"âœ“ åˆ›å»ºèŠå¤©ä¼šè¯: {chat_session_id}")
            
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            await self.chat_dao.add_message(
                session_id=chat_session_id,
                role="user",
                content=query
            )
            print(f"âœ“ ä¿å­˜ç”¨æˆ·æ¶ˆæ¯")
            
            # è·å–æŠ¥å‘Šå†…å®¹
            report = result.get("report", "")
            if not report:
                # å°è¯•ä»ç¼“å­˜è·å–
                export_data = await self.export_session_data(session_id)
                if export_data:
                    report = export_data.get("report", "")
            
            if not report:
                print(f"âš ï¸ æœªæ‰¾åˆ°æŠ¥å‘Šå†…å®¹")
                return False
            
            # ä¿å­˜åŠ©æ‰‹å›å¤ï¼ˆç ”ç©¶æŠ¥å‘Šï¼‰
            await self.chat_dao.add_message(
                session_id=chat_session_id,
                role="assistant",
                content=report
            )
            print(f"âœ“ ä¿å­˜ç ”ç©¶æŠ¥å‘Šåˆ°èŠå¤©å†å²")
            
            return True
            
        except Exception as e:
            print(f"âœ— ä¿å­˜åˆ°èŠå¤©å†å²å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    async def delete_session(self, session_id: str) -> Dict[str, Any]:
        """
        åˆ é™¤ç ”ç©¶ä¼šè¯

        Args:
            session_id: ä¼šè¯ID

        Returns:
            åˆ é™¤ç»“æœ
        """
        try:
            # å¦‚æœæ˜¯æ´»è·ƒä¼šè¯ï¼Œå…ˆä¸­æ–­
            if session_id in self.active_researchers:
                await self.interrupt_research(session_id)

            # ä»æ•°æ®åº“åˆ é™¤
            await self.research_dao.delete_research_session(session_id)

            return {
                "success": True,
                "session_id": session_id,
                "message": "ç ”ç©¶ä¼šè¯å·²åˆ é™¤"
            }

        except Exception as e:
            return {
                "success": False,
                "error": f"åˆ é™¤ä¼šè¯å¤±è´¥: {str(e)}",
                "session_id": session_id
            }

    async def search_research_content(
        self,
        query: str,
        user_id: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        æœç´¢ç ”ç©¶å†…å®¹

        Args:
            query: æœç´¢æŸ¥è¯¢
            user_id: ç”¨æˆ·IDï¼Œç”¨äºè¿‡æ»¤
            limit: ç»“æœæ•°é‡é™åˆ¶

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            # å¦‚æœæŒ‡å®šäº†ç”¨æˆ·IDï¼Œéœ€è¦å…ˆè·å–ç”¨æˆ·çš„ä¼šè¯ID
            session_ids = None
            if user_id:
                user_sessions = await self.get_user_sessions(user_id)
                session_ids = [session["id"] for session in user_sessions]

            # æ‰§è¡Œæœç´¢
            results = []
            if session_ids:
                for session_id in session_ids:
                    session_results = await self.research_dao.search_research_content(
                        query=query,
                        limit=limit // len(session_ids) + 1,
                        session_id=session_id
                    )
                    results.extend(session_results)
            else:
                results = await self.research_dao.search_research_content(
                    query=query,
                    limit=limit
                )

            return results[:limit]

        except Exception as e:
            print(f"æœç´¢ç ”ç©¶å†…å®¹å¤±è´¥: {str(e)}")
            return []

    async def get_research_statistics(self, user_id: Optional[str] = None) -> Dict[str, Any]:
        """
        è·å–ç ”ç©¶ç»Ÿè®¡ä¿¡æ¯

        Args:
            user_id: ç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™è·å–å…¨å±€ç»Ÿè®¡

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        try:
            return await self.research_dao.get_research_statistics(user_id=user_id)
        except Exception as e:
            print(f"è·å–ç ”ç©¶ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {}

    async def cleanup_inactive_sessions(self, inactive_hours: int = 24) -> Dict[str, Any]:
        """
        æ¸…ç†éæ´»è·ƒä¼šè¯

        Args:
            inactive_hours: éæ´»è·ƒæ—¶é—´é˜ˆå€¼ï¼ˆå°æ—¶ï¼‰

        Returns:
            æ¸…ç†ç»“æœ
        """
        try:
            # æ¸…ç†å†…å­˜ç®¡ç†å™¨ä¸­çš„éæ´»è·ƒä¼šè¯
            await self.memory_manager.cleanup_inactive_sessions(inactive_hours)

            # æ¸…ç†æ´»è·ƒç ”ç©¶è€…åˆ—è¡¨
            cleaned_sessions = []
            cutoff_time = datetime.now() - timedelta(hours=inactive_hours)

            for session_id, researcher in list(self.active_researchers.items()):
                try:
                    session_info = await self.research_dao.get_research_session(session_id)
                    if session_info and session_info.get("updated_at"):
                        updated_at = datetime.fromisoformat(session_info["updated_at"])
                        if updated_at < cutoff_time:
                            await self.interrupt_research(session_id)
                            cleaned_sessions.append(session_id)
                except Exception as e:
                    print(f"æ¸…ç†ä¼šè¯ {session_id} æ—¶å‡ºé”™: {str(e)}")

            return {
                "success": True,
                "cleaned_sessions": cleaned_sessions,
                "message": f"æ¸…ç†äº† {len(cleaned_sessions)} ä¸ªéæ´»è·ƒä¼šè¯"
            }

        except Exception as e:
            return {
                "success": False,
                "error": f"æ¸…ç†éæ´»è·ƒä¼šè¯å¤±è´¥: {str(e)}"
            }

    async def _generate_final_report(
        self,
        session_id: str,
        researcher: DeepResearchAgent
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆæœ€ç»ˆçš„å®Œæ•´ç ”ç©¶æŠ¥å‘Šï¼ˆåªåœ¨ç ”ç©¶å®Œæˆæ—¶è°ƒç”¨ä¸€æ¬¡ï¼‰
        
        Args:
            session_id: ä¼šè¯ID
            researcher: ç ”ç©¶ä»£ç†å®ä¾‹
            
        Returns:
            å®Œæ•´çš„æŠ¥å‘Šæ•°æ®å­—å…¸
        """
        try:
            # ä»ä»£ç†è·å–æ•°æ®
            agent_data = await researcher.export_session_data()
            
            # è·å–ç¼“å­˜çš„ä¼šè¯ä¿¡æ¯
            cached_session = self.session_cache.get(session_id, {})
            
            # ç¡®ä¿æ—¥æœŸæ—¶é—´å­—æ®µæ˜¯å­—ç¬¦ä¸²æ ¼å¼
            created_at = agent_data.get("created_at")
            if isinstance(created_at, datetime):
                created_at = created_at.isoformat()
            elif not created_at:
                created_at = cached_session.get("created_at", datetime.now().isoformat())
            
            updated_at = datetime.now().isoformat()
            
            # åºåˆ—åŒ– findings å’Œ citations
            findings = agent_data.get("research_findings", [])
            serialized_findings = []
            for finding in findings:
                serialized_finding = dict(finding) if not isinstance(finding, dict) else finding.copy()
                if 'id' in serialized_finding and not isinstance(serialized_finding['id'], str):
                    serialized_finding['id'] = str(serialized_finding['id'])
                if 'created_at' in serialized_finding:
                    if isinstance(serialized_finding['created_at'], datetime):
                        serialized_finding['created_at'] = serialized_finding['created_at'].isoformat()
                    elif not isinstance(serialized_finding['created_at'], str):
                        serialized_finding['created_at'] = str(serialized_finding['created_at'])
                serialized_findings.append(serialized_finding)
            
            citations = agent_data.get("citations", [])
            serialized_citations = []
            for citation in citations:
                serialized_citation = dict(citation) if not isinstance(citation, dict) else citation.copy()
                if 'id' in serialized_citation and not isinstance(serialized_citation['id'], str):
                    serialized_citation['id'] = str(serialized_citation['id'])
                if 'created_at' in serialized_citation:
                    if isinstance(serialized_citation['created_at'], datetime):
                        serialized_citation['created_at'] = serialized_citation['created_at'].isoformat()
                    elif not isinstance(serialized_citation['created_at'], str):
                        serialized_citation['created_at'] = str(serialized_citation['created_at'])
                serialized_citations.append(serialized_citation)
            
            # ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬
            report = agent_data.get("report")
            if not report:
                report = await self._generate_report_from_data(
                    serialized_findings,
                    serialized_citations,
                    cached_session.get("title", "ç ”ç©¶ä¼šè¯")
                )
            
            # æ„å»ºå®Œæ•´æŠ¥å‘Š
            final_report = {
                "session_info": {
                    "id": agent_data.get("session_id", session_id),
                    "user_id": cached_session.get("user_id"),
                    "title": cached_session.get("title", "ç ”ç©¶ä¼šè¯"),
                    "status": "completed",
                    "created_at": created_at,
                    "updated_at": updated_at,
                    "ended_at": updated_at,
                    "findings_count": len(serialized_findings),
                    "citations_count": len(serialized_citations)
                },
                "findings": serialized_findings,
                "citations": serialized_citations,
                "memory": agent_data.get("short_memory", []),
                "report": report,
                "tools_used": agent_data.get("tools_used", []),
                "exported_at": updated_at
            }
            
            return final_report
            
        except Exception as e:
            print(f"âœ— ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    async def _generate_report_from_data(
        self,
        findings: List[Dict[str, Any]],
        citations: List[Dict[str, Any]],
        title: str
    ) -> str:
        """
        ä»ç ”ç©¶æ•°æ®ç”ŸæˆæŠ¥å‘Š
        
        Args:
            findings: ç ”ç©¶å‘ç°åˆ—è¡¨
            citations: å¼•ç”¨åˆ—è¡¨
            title: ç ”ç©¶æ ‡é¢˜
            
        Returns:
            æ ¼å¼åŒ–çš„ç ”ç©¶æŠ¥å‘Š
        """
        report = f"# ç ”ç©¶æŠ¥å‘Š\n\n"
        report += f"## ç ”ç©¶ä¸»é¢˜\n{title}\n\n"
        report += f"## ç ”ç©¶æ—¶é—´\n{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"

        if findings:
            report += "## ä¸»è¦å‘ç°\n\n"
            for i, finding in enumerate(findings, 1):
                source_type = finding.get("source_type", "æœªçŸ¥")
                content = finding.get("content", "")
                relevance = finding.get("relevance_score", 0)

                report += f"### å‘ç° {i} [{source_type}æ¥æº]\n"
                report += f"{content}\n\n"
                report += f"ç›¸å…³æ€§è¯„åˆ†: {relevance:.2f}\n\n"

        if citations:
            report += "## å‚è€ƒæ–‡çŒ®\n\n"
            for i, citation in enumerate(citations, 1):
                title_text = citation.get("title", "æ— æ ‡é¢˜")
                authors = citation.get("authors", [])
                year = citation.get("publication_year", "æœªçŸ¥")
                url = citation.get("source_url", "")

                report += f"{i}. {title_text}\n"
                if authors:
                    report += f"   ä½œè€…: {', '.join(authors)}\n"
                if year != "æœªçŸ¥":
                    report += f"   å‘è¡¨å¹´ä»½: {year}\n"
                if url:
                    report += f"   é“¾æ¥: {url}\n\n"

        report += f"\n## ç»Ÿè®¡ä¿¡æ¯\n\n"
        report += f"- å‘ç°æ•°é‡: {len(findings)}\n"
        report += f"- å¼•ç”¨æ•°é‡: {len(citations)}\n"

        return report

    async def _get_web_search_api_key(self) -> Optional[str]:
        """
        è·å–ç½‘ç»œæœç´¢APIå¯†é’¥

        Returns:
            APIå¯†é’¥å­—ç¬¦ä¸²
        """
        # è¿™é‡Œåº”è¯¥ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è·å–
        import os
        return os.getenv("BIGMODEL_API_KEY") or os.getenv("WEB_SEARCH_API_KEY")

    async def validate_session_access(self, session_id: str, user_id: str) -> bool:
        """
        éªŒè¯ç”¨æˆ·å¯¹ä¼šè¯çš„è®¿é—®æƒé™

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID

        Returns:
            æ˜¯å¦æœ‰è®¿é—®æƒé™
        """
        try:
            # å…ˆå°è¯•ä»æ•°æ®åº“è·å–
            session_info = await self.research_dao.get_research_session(session_id)
            
            # å¦‚æœæ•°æ®åº“æœªå¯ç”¨ï¼Œä»å†…å­˜ç¼“å­˜è·å–
            if not session_info and session_id in self.session_cache:
                session_info = self.session_cache[session_id]
            
            if not session_info:
                return False

            # å¦‚æœä¼šè¯æ²¡æœ‰ç”¨æˆ·IDï¼Œåˆ™å…è®¸æ‰€æœ‰ç”¨æˆ·è®¿é—®ï¼ˆå…¬å…±ä¼šè¯ï¼‰
            if not session_info.get("user_id"):
                return True

            # æ£€æŸ¥ç”¨æˆ·IDåŒ¹é…
            return session_info.get("user_id") == user_id

        except Exception as e:
            print(f"éªŒè¯ä¼šè¯è®¿é—®æƒé™å¤±è´¥: {str(e)}")
            return False

    async def format_final_report(
        self,
        session_id: str,
        export_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        å°†åŸå§‹å¯¼å‡ºæ•°æ®æ ¼å¼åŒ–ä¸ºå‰ç«¯å‹å¥½çš„æœ€ç»ˆæŠ¥å‘Šï¼ˆåŒ…å«å®Œæ•´è¯æ®é“¾ï¼‰
        
        Args:
            session_id: ä¼šè¯ID
            export_data: ä»export_session_dataè·å–çš„åŸå§‹æ•°æ®
            
        Returns:
            æ ¼å¼åŒ–åçš„æŠ¥å‘Šå­—å…¸
        """
        try:
            # âœ… ä¼˜å…ˆä½¿ç”¨ Agent ç”Ÿæˆçš„æŠ¥å‘Š
            agent_report = export_data.get("report")
            if agent_report and isinstance(agent_report, str) and len(agent_report) > 100:
                print(f"âœ“ ä½¿ç”¨ Agent ç”Ÿæˆçš„æŠ¥å‘Šï¼Œé•¿åº¦: {len(agent_report)} å­—ç¬¦")
                return {
                    "title": "æ·±åº¦ç ”ç©¶æŠ¥å‘Š",
                    "agent_report": agent_report,  # âœ… ä¿å­˜å®Œæ•´çš„ Agent æŠ¥å‘Š
                    "metadata": {
                        "generated_at": datetime.now().isoformat(),
                        "report_source": "agent",
                        "report_length": len(agent_report)
                    }
                }
            
            # å¦‚æœæ²¡æœ‰ Agent æŠ¥å‘Šï¼Œåˆ™ä» findings ç”Ÿæˆ
            print(f"âš ï¸ æœªæ‰¾åˆ° Agent æŠ¥å‘Šï¼Œä» findings ç”Ÿæˆ")
            
            # æå–å…³é”®æ•°æ®
            session_info = export_data.get("session_info", {})
            findings = export_data.get("findings", [])
            citations = export_data.get("citations", [])
            tools_used = export_data.get("tools_used", [])
            
            # æ„å»ºè¯æ®é“¾
            evidence_chain = self._build_evidence_chain(findings, citations)
            
            # æå–å…³é”®å‘ç°
            key_findings = self._extract_key_findings(findings)
            
            # æ„å»ºæŠ¥å‘Š
            formatted_report = {
                "title": session_info.get("title", "æ·±åº¦ç ”ç©¶æŠ¥å‘Š"),
                "summary": self._generate_executive_summary(findings),
                "sections": self._generate_report_sections(findings),
                "methodology": self._generate_methodology_section(tools_used),
                "conclusions": self._generate_conclusions(findings),
                "references": self._format_references(citations),
                "key_findings": key_findings,
                "evidence_chain": evidence_chain,
                "metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "total_findings": len(findings),
                    "total_citations": len(citations),
                    "quality_score": self._calculate_quality_score(findings, citations),
                    "quality_level": self._determine_quality_level(findings, citations),
                    "tools_count": len(tools_used),
                    "evidence_strength": evidence_chain.get("overall_strength", "medium")
                }
            }
            
            return formatted_report
            
        except Exception as e:
            print(f"æ ¼å¼åŒ–æŠ¥å‘Šå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "title": "æŠ¥å‘Šç”Ÿæˆå¤±è´¥",
                "error": str(e),
                "summary": "",
                "sections": [],
                "methodology": "",
                "conclusions": "",
                "references": "",
                "key_findings": [],
                "evidence_chain": {},
                "metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "total_findings": 0,
                    "total_citations": 0,
                    "quality_score": 0.0,
                    "quality_level": "low",
                    "tools_count": 0,
                    "evidence_strength": "weak"
                }
            }

    def _generate_executive_summary(self, findings: List[Dict]) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        if not findings:
            return "æœªæ‰¾åˆ°ç›¸å…³å‘ç°ã€‚"
        
        # é€‰æ‹©ç›¸å…³æ€§æœ€é«˜çš„å‰3ä¸ªå‘ç°
        top_findings = sorted(
            findings,
            key=lambda x: x.get("relevance_score", 0),
            reverse=True
        )[:3]
        
        summary = "## æ‰§è¡Œæ‘˜è¦\n\n"
        for i, finding in enumerate(top_findings, 1):
            content = finding.get("content", "")
            # é™åˆ¶é•¿åº¦
            if len(content) > 300:
                content = content[:300] + "..."
            summary += f"- {content}\n\n"
        
        return summary

    def _generate_report_sections(self, findings: List[Dict]) -> List[Dict]:
        """æŒ‰æ¥æºç±»å‹ç”ŸæˆæŠ¥å‘Šåˆ†æ®µ"""
        sections = []
        
        # æŒ‰æ¥æºåˆ†ç±»
        findings_by_source = {}
        for finding in findings:
            source = finding.get("source_type", "å…¶ä»–")
            if source not in findings_by_source:
                findings_by_source[source] = []
            findings_by_source[source].append(finding)
        
        # æ¥æºç±»å‹çš„æ˜¾ç¤ºåç§°
        source_names = {
            "web": "ğŸŒ ç½‘ç»œæœç´¢å‘ç°",
            "wikipedia": "ğŸ“š ç»´åŸºç™¾ç§‘çŸ¥è¯†åº“",
            "arxiv": "ğŸ“– å­¦æœ¯è®ºæ–‡è§è§£",
            "image": "ğŸ–¼ï¸ å›¾åƒåˆ†æç»“æœ",
            "synthesis": "ğŸ” ç»¼åˆåˆ†æ"
        }
        
        for source, source_findings in findings_by_source.items():
            # å–ç›¸å…³æ€§æœ€é«˜çš„2ä¸ªå‘ç°
            top_findings = sorted(
                source_findings,
                key=lambda x: x.get("relevance_score", 0),
                reverse=True
            )[:2]
            
            section = {
                "title": source_names.get(source, f"ğŸ“Œ {source}"),
                "content": "\n\n".join([
                    f.get("content", "")[:500] for f in top_findings
                ])
            }
            sections.append(section)
        
        return sections

    def _generate_methodology_section(self, tools_used: List[str]) -> str:
        """ç”Ÿæˆæ–¹æ³•è®ºéƒ¨åˆ†"""
        methodology = "## ç ”ç©¶æ–¹æ³•\n\n"
        methodology += "æœ¬ç ”ç©¶é‡‡ç”¨äº†ä»¥ä¸‹å·¥å…·å’Œæ–¹æ³•è¿›è¡Œå¤šæºä¿¡æ¯æ”¶é›†å’Œåˆ†æï¼š\n\n"
        
        tool_descriptions = {
            "web_search": "ğŸ” äº’è”ç½‘æœç´¢ - è·å–æœ€æ–°çš„ç½‘ç»œä¿¡æ¯å’Œæ–°é—»",
            "search_wikipedia": "ğŸ“š ç»´åŸºç™¾ç§‘æŸ¥è¯¢ - æ”¶é›†æƒå¨çš„èƒŒæ™¯çŸ¥è¯†",
            "search_arxiv_papers": "ğŸ“– å­¦æœ¯è®ºæ–‡æ£€ç´¢ - è·å–åŒè¡Œè¯„å®¡çš„å­¦æœ¯ç ”ç©¶",
            "analyze_image": "ğŸ–¼ï¸ å›¾åƒåˆ†æ - å¤„ç†å’Œè§£é‡Šè§†è§‰å†…å®¹",
            "synthesize_research_findings": "âœ¨ æ™ºèƒ½åˆæˆ - æ•´åˆå¤šæºä¿¡æ¯å½¢æˆç»“è®º"
        }
        
        if tools_used:
            for tool in tools_used:
                description = tool_descriptions.get(tool, f"ğŸ”§ {tool}")
                methodology += f"â€¢ {description}\n"
        else:
            methodology += "â€¢ å¤šæºä¿¡æ¯æ”¶é›†å’Œåˆ†æ\n"
        
        return methodology

    def _generate_conclusions(self, findings: List[Dict]) -> str:
        """ç”Ÿæˆç»“è®ºéƒ¨åˆ†"""
        conclusions = "## ä¸»è¦ç»“è®º\n\n"
        
        if not findings:
            return conclusions + "åŸºäºç°æœ‰æ•°æ®æ— æ³•å¾—å‡ºç¡®å®šçš„ç»“è®ºã€‚"
        
        # æŒ‰ç›¸å…³æ€§æ’åºï¼Œå–å‰5ä¸ª
        sorted_findings = sorted(
            findings,
            key=lambda x: x.get("relevance_score", 0),
            reverse=True
        )[:5]
        
        for i, finding in enumerate(sorted_findings, 1):
            content = finding.get("content", "")
            # æå–å‰2å¥ä½œä¸ºç»“è®º
            sentences = content.split("ã€‚")[:2]
            conclusion = "ã€‚".join(sentences)
            if not conclusion.endswith("ã€‚"):
                conclusion += "ã€‚"
            conclusions += f"{i}. {conclusion}\n\n"
        
        return conclusions

    def _format_references(self, citations: List[Dict]) -> str:
        """æ ¼å¼åŒ–å‚è€ƒæ–‡çŒ®"""
        if not citations:
            return "## å‚è€ƒæ–‡çŒ®\n\næœªæ‰¾åˆ°ç›¸å…³å¼•ç”¨ã€‚"
        
        references = "## å‚è€ƒæ–‡çŒ®\n\n"
        for i, citation in enumerate(citations, 1):
            title = citation.get("title", "Unknown")
            authors = citation.get("authors", [])
            year = citation.get("publication_year", "")
            url = citation.get("source_url", "")
            
            authors_str = ", ".join(authors[:3]) if authors else "Unknown"  # æœ€å¤šæ˜¾ç¤º3ä¸ªä½œè€…
            
            ref_text = f"{i}. {title}"
            if authors_str:
                ref_text += f" - {authors_str}"
            if authors and len(authors) > 3:
                ref_text += f" ç­‰"
            if year:
                ref_text += f" ({year})"
            if url:
                ref_text += f"\n   [é“¾æ¥]({url})"
            
            references += ref_text + "\n\n"
        
        return references

    def _calculate_quality_score(self, findings: List[Dict], citations: List[Dict]) -> float:
        """è®¡ç®—æŠ¥å‘Šè´¨é‡è¯„åˆ†ï¼ˆ0-1ï¼‰"""
        score = 0.0
        
        # å‘ç°æ•°é‡è¯„åˆ†ï¼ˆæƒé‡ 30%ï¼‰
        if len(findings) >= 15:
            score += 0.30
        elif len(findings) >= 10:
            score += 0.25
        elif len(findings) >= 5:
            score += 0.15
        elif len(findings) > 0:
            score += 0.05
        
        # å¹³å‡ç›¸å…³æ€§è¯„åˆ†ï¼ˆæƒé‡ 40%ï¼‰
        if findings:
            avg_relevance = sum(f.get("relevance_score", 0) for f in findings) / len(findings)
            score += avg_relevance * 0.40
        
        # å¼•ç”¨æ•°é‡è¯„åˆ†ï¼ˆæƒé‡ 30%ï¼‰
        if len(citations) >= 10:
            score += 0.30
        elif len(citations) >= 5:
            score += 0.20
        elif len(citations) >= 3:
            score += 0.12
        elif len(citations) > 0:
            score += 0.05
        
        return min(score, 1.0)

    def _determine_quality_level(self, findings: List[Dict], citations: List[Dict]) -> str:
        """ç¡®å®šè¯æ®è´¨é‡ç­‰çº§"""
        score = self._calculate_quality_score(findings, citations)
        
        if score >= 0.8:
            return "excellent"
        elif score >= 0.6:
            return "good"
        elif score >= 0.4:
            return "medium"
        elif score >= 0.2:
            return "fair"
        else:
            return "low"

    def _build_evidence_chain(self, findings: List[Dict], citations: List[Dict]) -> Dict[str, Any]:
        """æ„å»ºè¯æ®é“¾æ•°æ®ç»“æ„"""
        try:
            # æŒ‰æ¥æºç±»å‹åˆ†ç»„
            findings_by_source = {}
            for finding in findings:
                source = finding.get("source_type", "other")
                if source not in findings_by_source:
                    findings_by_source[source] = []
                findings_by_source[source].append(finding)
            
            # è®¡ç®—æ¯ä¸ªæ¥æºçš„å¹³å‡ç›¸å…³æ€§
            source_strengths = {}
            for source, source_findings in findings_by_source.items():
                avg_relevance = sum(f.get("relevance_score", 0) for f in source_findings) / len(source_findings)
                source_strengths[source] = {
                    "count": len(source_findings),
                    "avg_relevance": avg_relevance,
                    "strength": "strong" if avg_relevance >= 0.7 else "medium" if avg_relevance >= 0.4 else "weak"
                }
            
            # æå–è¯æ®å…³ç³»
            relationships = self._extract_evidence_relationships(findings)
            
            # è®¡ç®—æ•´ä½“è¯æ®å¼ºåº¦
            overall_avg = sum(f.get("relevance_score", 0) for f in findings) / len(findings) if findings else 0
            overall_strength = "strong" if overall_avg >= 0.7 else "medium" if overall_avg >= 0.4 else "weak"
            
            return {
                "sources": findings_by_source,
                "source_strengths": source_strengths,
                "relationships": relationships,
                "overall_strength": overall_strength,
                "total_evidence_points": len(findings),
                "citation_support": len(citations)
            }
            
        except Exception as e:
            print(f"æ„å»ºè¯æ®é“¾å¤±è´¥: {str(e)}")
            return {
                "sources": {},
                "source_strengths": {},
                "relationships": [],
                "overall_strength": "weak",
                "total_evidence_points": 0,
                "citation_support": 0
            }

    def _extract_evidence_relationships(self, findings: List[Dict]) -> List[Dict]:
        """æå–è¯æ®ä¹‹é—´çš„å…³ç³»"""
        relationships = []
        
        try:
            # ç®€å•çš„å…³ç³»æå–ï¼šæ‰¾å‡ºç›¸å…³æ€§é«˜çš„å‘ç°å¯¹
            sorted_findings = sorted(findings, key=lambda x: x.get("relevance_score", 0), reverse=True)
            
            # åªå¤„ç†å‰10ä¸ªæœ€ç›¸å…³çš„å‘ç°
            top_findings = sorted_findings[:10]
            
            for i, finding1 in enumerate(top_findings):
                for finding2 in top_findings[i+1:]:
                    # å¦‚æœä¸¤ä¸ªå‘ç°æ¥è‡ªä¸åŒæ¥æºä½†ç›¸å…³æ€§éƒ½å¾ˆé«˜ï¼Œè®¤ä¸ºå®ƒä»¬ç›¸äº’æ”¯æŒ
                    if (finding1.get("source_type") != finding2.get("source_type") and
                        finding1.get("relevance_score", 0) >= 0.6 and
                        finding2.get("relevance_score", 0) >= 0.6):
                        
                        relationships.append({
                            "type": "supports",
                            "from_source": finding1.get("source_type"),
                            "to_source": finding2.get("source_type"),
                            "strength": min(finding1.get("relevance_score", 0), finding2.get("relevance_score", 0))
                        })
            
            # é™åˆ¶å…³ç³»æ•°é‡
            return relationships[:20]
            
        except Exception as e:
            print(f"æå–è¯æ®å…³ç³»å¤±è´¥: {str(e)}")
            return []

    def _extract_key_findings(self, findings: List[Dict]) -> List[Dict]:
        """æå–å…³é”®å‘ç°ï¼ˆæœ€é‡è¦çš„5-10ä¸ªï¼‰"""
        try:
            # æŒ‰ç›¸å…³æ€§æ’åº
            sorted_findings = sorted(
                findings,
                key=lambda x: x.get("relevance_score", 0),
                reverse=True
            )
            
            # æå–å‰8ä¸ªæœ€ç›¸å…³çš„å‘ç°
            key_findings = []
            for finding in sorted_findings[:8]:
                key_findings.append({
                    "content": finding.get("content", "")[:300],  # é™åˆ¶é•¿åº¦
                    "source_type": finding.get("source_type", "unknown"),
                    "relevance_score": finding.get("relevance_score", 0),
                    "quality": "high" if finding.get("relevance_score", 0) >= 0.7 else "medium" if finding.get("relevance_score", 0) >= 0.4 else "low"
                })
            
            return key_findings
            
        except Exception as e:
            print(f"æå–å…³é”®å‘ç°å¤±è´¥: {str(e)}")
            return []

    def generate_full_report_text(self, formatted_report: Dict[str, Any]) -> str:
        """
        å°†æ ¼å¼åŒ–çš„æŠ¥å‘Šè½¬æ¢ä¸ºå®Œæ•´çš„ Markdown æ–‡æœ¬
        
        Args:
            formatted_report: æ ¼å¼åŒ–åçš„æŠ¥å‘Šå­—å…¸
            
        Returns:
            å®Œæ•´çš„æŠ¥å‘Šæ–‡æœ¬ï¼ˆMarkdown æ ¼å¼ï¼‰
        """
        try:
            # âœ… ä¼˜å…ˆè¿”å› Agent ç”Ÿæˆçš„å®Œæ•´æŠ¥å‘Š
            agent_report = formatted_report.get("agent_report")
            if agent_report:
                print(f"âœ“ è¿”å› Agent å®Œæ•´æŠ¥å‘Šï¼Œé•¿åº¦: {len(agent_report)} å­—ç¬¦")
                return agent_report
            
            # å¦‚æœæ²¡æœ‰ Agent æŠ¥å‘Šï¼Œåˆ™ä»ç»“æ„åŒ–æ•°æ®ç”Ÿæˆ
            print(f"âš ï¸ ä»ç»“æ„åŒ–æ•°æ®ç”ŸæˆæŠ¥å‘Š")
            
            report_text = ""
            
            # æ ‡é¢˜
            title = formatted_report.get("title", "æ·±åº¦ç ”ç©¶æŠ¥å‘Š")
            report_text += f"# {title}\n\n"
            
            # å…ƒæ•°æ®
            metadata = formatted_report.get("metadata", {})
            if metadata:
                report_text += "---\n\n"
                report_text += f"**ç”Ÿæˆæ—¶é—´**: {metadata.get('generated_at', '')}\n\n"
                
                # åªåœ¨æœ‰è´¨é‡è¯„åˆ†æ—¶æ˜¾ç¤º
                if metadata.get('quality_score'):
                    report_text += f"**è´¨é‡è¯„åˆ†**: {int(metadata.get('quality_score', 0) * 100)}% ({metadata.get('quality_level', 'unknown')})\n\n"
                
                report_text += f"**å‘ç°æ•°é‡**: {metadata.get('total_findings', 0)} | "
                report_text += f"**å¼•ç”¨æ•°é‡**: {metadata.get('total_citations', 0)} | "
                report_text += f"**å·¥å…·ä½¿ç”¨**: {metadata.get('tools_count', 0)}\n\n"
                report_text += "---\n\n"
            
            # æ‰§è¡Œæ‘˜è¦
            summary = formatted_report.get("summary", "")
            if summary:
                report_text += summary + "\n\n"
            
            # æŠ¥å‘Šç« èŠ‚
            sections = formatted_report.get("sections", [])
            if sections:
                for section in sections:
                    report_text += f"## {section.get('title', 'ç« èŠ‚')}\n\n"
                    report_text += f"{section.get('content', '')}\n\n"
            
            # ç ”ç©¶æ–¹æ³•
            methodology = formatted_report.get("methodology", "")
            if methodology:
                report_text += methodology + "\n\n"
            
            # ä¸»è¦ç»“è®º
            conclusions = formatted_report.get("conclusions", "")
            if conclusions:
                report_text += conclusions + "\n\n"
            
            # å‚è€ƒæ–‡çŒ®
            references = formatted_report.get("references", "")
            if references:
                report_text += references + "\n\n"
            
            return report_text
            
        except Exception as e:
            print(f"ç”Ÿæˆå®Œæ•´æŠ¥å‘Šæ–‡æœ¬å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return f"# æŠ¥å‘Šç”Ÿæˆå¤±è´¥\n\né”™è¯¯: {str(e)}"
