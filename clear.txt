# 深度研究平台 - 完整进程分析

## 项目概述
这是一个基于多智能体架构的深度研究平台，支持智能模型路由、工具调用、RAG检索等功能。平台采用FastAPI后端 + Vue前端架构，支持多种LLM提供商的动态切换。

## 深度研究完整流程

### 1. 用户输入阶段
**触发入口:**
- 前端通过 `/api/research` 或 `/api/agents/call` 接口发起研究请求
- 支持简单聊天(`/api/chat`)和复杂研究(`/api/research`)两种模式

**输入处理:**
- 消息通过 `src/serve/sanitizer.py` 进行安全过滤
- 认证通过 `src/api/auth.py` 和JWT验证
- 配额检查通过 `src/api/quota.py` 限制使用

### 2. 模型路由与选择阶段
**智能路由器 (`src/llms/router.py`):**
- 基于任务类型(PROVIDER_PRIORITY配置)选择最优提供商
- 支持5个主要提供商: Ollama, DeepSeek, Kimi, Doubao, ZhipuAI
- 考虑因素: 质量、成本、速度、功能支持

**路由决策逻辑:**
```python
# 任务类型映射到优先级
PROVIDER_PRIORITY = {
  "research": ["zhipuai", "doubao", "kimi", "deepseek", "ollama"],
  "reasoning": ["zhipuai", "deepseek", "ollama", "doubao", "kimi"],
  "vision": ["zhipuai", "doubao", "ollama", "deepseek"]
}
```

**模型能力评估:**
- 质量评分(0-1): ZhipuAI GLM-4.6(0.98), DeepSeek(0.85-0.95)
- 速度评分(0-1): Doubao(0.95), ZhipuAI-Flash(0.95)
- 功能支持: 函数调用、视觉理解、JSON输出等

### 3. Agent执行阶段

#### 3.1 ReAct Agent核心循环 (`src/agents/react_agent.py`)
**ReAct模式: Reasoning → Acting → Observing**

**推理阶段 (Enhanced Reasoning):**
- 思维链提示 (Chain-of-Thought)
- 任务复杂度检测和分解
- 多轮推理历史追踪
- 置信度自动评估

**行动阶段:**
- 工具调用执行
- 支持Web搜索、学术检索、维基百科查询等
- 异步并发执行多个工具

**观察阶段:**
- 工具结果解析和格式化
- 上下文更新维护

#### 3.2 Research Agent增强功能 (`src/agents/research_agent.py`)
**研究专用能力:**
- 多源信息收集和交叉验证
- 信息源可信度评估 (学术0.9, 政府0.85, 新闻0.6)
- 参考资料管理和追踪
- 研究时间线记录

### 4. 工具调用系统 (`src/tools/`)

#### 4.1 搜索工具
**Web搜索 (`web_search.py`):**
- 支持Tavily, DuckDuckGo搜索引擎
- 智能回退机制
- 结果去重和排序

**学术搜索 (`arxiv_tool.py`):**
- ArXiv论文检索
- 支持关键词和作者搜索

**维基百科 (`wikipedia_tool.py`):**
- 多语言支持
- 结构化信息提取

#### 4.2 代码执行 (`code_exec.py`)
- 安全的代码执行环境
- 支持Python代码运行和测试

### 5. RAG检索增强 (`src/core/rag/`)

#### 5.1 两阶段检索
**第一阶段:** 向量检索 (vector_store.py)
- 支持pgvector和ChromaDB
- 语义相似度计算

**第二阶段:** 重排序 (reranker.py)
- 交叉编码器重新排序
- 提高检索准确性

#### 5.2 检索流程
1. 查询预处理和扩展
2. 多源检索 (文档、网页、学术论文)
3. 相关性重排序
4. 上下文整合

### 6. 多智能体协作 (`src/graph/`)

#### 6.1 LangGraph工作流 (`builder.py`)
**协作模式:**
- 顺序协作: Agent依次执行
- 并行协作: 多个Agent同时执行
- 层次协作: 协调者 + 工作者模式

#### 6.2 Agent角色
- **Supervisor**: 任务分配和协调
- **Researcher**: 信息收集和分析
- **Writer**: 报告生成和撰写

### 7. Token计算与成本控制

#### 7.1 Token追踪 (`src/utils/cost_tracker.py`)
**计算维度:**
- 输入Token: 用户查询 + 系统提示 + 历史上下文
- 输出Token: 模型生成的内容
- 缓存Token: DeepSeek支持输入缓存优化

**成本模型:**
```python
# DeepSeek价格 (百万tokens)
input_cached: 0.2元     # 缓存命中
input_uncached: 2元     # 缓存未命中
output: 3元            # 输出内容
```

#### 7.2 预算控制
- 每请求预算上限: 0.1美元
- 速率限制: 基于提供商能力动态调整
- 成本优化: 自动选择性价比高的模型

### 8. 输出生成与格式化

#### 8.1 报告生成
- Markdown格式输出
- 支持代码高亮和表格
- 自动目录生成

#### 8.2 导出功能 (`src/export/`)
- **Markdown**: 结构化文档导出
- **PPT**: 自动幻灯片生成 (python-pptx)
- **TTS**: 文本转语音 (EdgeTTS)
- **PDF**: 文档转换

### 9. 会话管理和记忆

#### 9.1 会话存储 (`src/serve/session_store.py`)
- Redis支持的高性能存储
- 会话状态持久化
- 研究报告缓存

#### 9.2 对话记忆 (`src/memory/`)
- 对话历史维护
- 上下文窗口管理 (自动分块)
- 长期记忆支持 (可选Mem0)

### 10. 监控与安全

#### 10.1 系统监控 (`src/middleware/monitoring.py`)
- 请求响应时间统计
- Token使用量监控
- 错误率追踪

#### 10.2 安全措施
- JWT认证和授权
- 输入 sanitization
- 内容审核工作流
- API密钥安全存储

## 模型切换机制

### 动态路由配置
**conf.yaml中的PROVIDER_PRIORITY:**
```yaml
PROVIDER_PRIORITY:
  research: ["zhipuai", "doubao", "kimi", "deepseek", "ollama"]
  reasoning: ["zhipuai", "deepseek", "ollama", "doubao", "kimi"]
  vision: ["zhipuai", "doubao", "ollama", "deepseek"]
```

### 切换触发条件
1. **任务类型变化**: 自动选择对应优先级的模型
2. **性能降级**: 当首选模型失败时自动切换
3. **成本优化**: 根据预算要求选择性价比模型
4. **功能需求**: 根据是否需要函数调用/视觉能力选择

### 模型能力矩阵
| 提供商 | 模型 | 质量 | 速度 | 成本 | 函数调用 | 视觉 | 上下文 |
|--------|------|------|------|------|----------|------|--------|
| ZhipuAI | GLM-4.6 | 0.98 | 0.85 | 中等 | ✅ | ❌ | 200K |
| DeepSeek | deepseek-reasoner | 0.95 | 0.7 | 低 | ❌ | ❌ | 32K |
| Doubao | doubao-seed-1-6-flash | 0.88 | 0.95 | 低 | ✅ | ❌ | 32K |
| Kimi | moonshot-v1-32k | 0.9 | 0.8 | 中等 | ✅ | ❌ | 32K |
| Ollama | qwen2.5:14b | 0.8 | 0.6 | 免费 | ✅ | ❌ | 32K |

## 项目TODO事项

### 🔴 高优先级 (核心功能)
1. **完成RAG系统集成**
   - [ ] 实现完整的pgvector检索流程
   - [ ] 添加文档预处理和分块逻辑
   - [ ] 集成重排序器提高检索质量

2. **完善多智能体工作流**
   - [ ] 实现supervisor_node, researcher_node, writer_node
   - [ ] 添加工作流状态管理和持久化
   - [ ] 实现人类反馈回路

3. **增强工具系统**
   - [ ] 完善学术论文搜索 (Google Scholar集成)
   - [ ] 添加代码执行安全沙箱
   - [ ] 实现工具结果缓存机制

### 🟡 中优先级 (用户体验)
4. **前端功能完善**
   - [ ] 实现实时研究进度显示
   - [ ] 添加研究报告可视化
   - [ ] 完善模型切换UI

5. **性能优化**
   - [ ] 实现请求并发控制
   - [ ] 添加响应缓存机制
   - [ ] 优化大文档处理性能

6. **监控和日志**
   - [ ] 完善错误追踪和告警
   - [ ] 添加详细的使用统计
   - [ ] 实现性能监控面板

### 🟢 低优先级 (扩展功能)
7. **新功能开发**
   - [ ] 支持多模态输入 (图像、音频)
   - [ ] 添加协作研究功能
   - [ ] 实现自定义Agent创建

8. **集成和兼容性**
   - [ ] 添加更多LLM提供商支持
   - [ ] 完善API文档和SDK
   - [ ] 实现数据导出格式扩展

## 技术债务和优化建议

### 代码质量
1. **统一错误处理**: 建立全局异常处理机制
2. **配置管理**: 使用Pydantic进行配置验证
3. **测试覆盖**: 添加单元测试和集成测试

### 性能优化
1. **异步处理**: 完善所有I/O操作的异步实现
2. **缓存策略**: 实现多级缓存 (内存→Redis→数据库)
3. **资源管理**: 添加连接池和资源限制

### 可扩展性
1. **插件系统**: 为工具和模型提供商设计插件接口
2. **微服务化**: 将核心功能拆分为独立服务
3. **API版本管理**: 实现API版本控制和兼容性保证

## 总结

深度研究平台实现了从用户输入到最终报告生成的完整AI研究流程，具备以下核心优势:

1. **智能路由**: 基于任务类型和质量要求自动选择最优模型
2. **多Agent协作**: 通过LangGraph实现复杂任务分解和协作
3. **工具集成**: 支持搜索、代码执行等多种外部工具调用
4. **RAG增强**: 两阶段检索提高信息获取质量
5. **成本控制**: 智能预算管理和Token使用优化

平台目前处于快速发展阶段，主要TODO集中在完善核心功能、优化性能和提升用户体验方面。
